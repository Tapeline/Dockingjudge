#
# --- common sections declaration ---
#



x-judgelet: &judgelet
  image: dockingjudge-unit
  expose: [ 8000 ]
  environment:
    IO_ENCODING: ${GLOBAL_ENCODING}
  healthcheck:
    test: curl --fail http://localhost:8000/ping || exit 1
    interval: 10s
    retries: 5
    start_period: 10s
    timeout: 10s
  networks:
    - judgelet_network



#
# --- services declaration ---
#


services:
  rabbitmq:
    image: rabbitmq:3.10.7-management
    hostname: rabbitmq
    restart: always
    environment:
      RABBITMQ_DEFAULT_USER: ${RMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RMQ_PASSWORD}
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: "-rabbit log_levels [{connection,error},{default,error}] disk_free_limit 2147483648"
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    expose:
      - "5672"
      - "15672"
    ports:
      - "15672:15672"
      - "5672:5672"
    healthcheck:
      test: rabbitmq-diagnostics check_port_connectivity
      interval: 1s
      timeout: 3s
      retries: 30
    networks:
      - main_network


  judgelet_0:
    <<: *judgelet
    ports:
      - "9000:8000"
  judgelet_1:
    <<: *judgelet
    ports:
      - "9001:8000"


  judge_service:
    hostname: judge_service
    build: JudgeService
    environment:
      RMQ_HOST: rabbitmq
      RMQ_USER: ${RMQ_USER}
      RMQ_PASS: ${RMQ_PASSWORD}
      S3_BASE_URL: http://minio:9000
    depends_on:
      rabbitmq:
        condition: service_healthy
      judgelet_0:
        condition: service_healthy
      judgelet_1:
        condition: service_healthy
    links:
      - rabbitmq
    networks:
      - main_network
      - judgelet_network


  account_service:
    build: AccountService
    hostname: account.service
    environment:
      ACCOUNT_SVC_SECURITY__SECRET_KEY: ${SECRET_KEY}
      ACCOUNT_SVC_POSTGRES__USERNAME: ${DB_USER}
      ACCOUNT_SVC_POSTGRES__PASSWORD: ${DB_PASS}
      ACCOUNT_SVC_POSTGRES__HOST: account_db
      ACCOUNT_SVC_POSTGRES__PORT: 5432
      ACCOUNT_SVC_MODE: production
      ACCOUNT_SVC_RABBIT__HOST: rabbitmq
      ACCOUNT_SVC_RABBIT__USERNAME: ${RMQ_USER}
      ACCOUNT_SVC_RABBIT__PASSWORD: ${RMQ_PASSWORD}
    ports:
      - "8001:8000"
    expose:
      - 8000
    networks:
      - main_network
    configs:
      - source: account_service_cfg
        target: /app/account_service.yml
    depends_on:
      account_db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  account_db:
    image: postgres:13.3
    hostname: account_db
    environment:
      POSTGRES_DB: account_db
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASS}
    ports:
      - "5500:5432"
    expose:
      - "5432"
    networks:
      - main_network
    volumes:
      - account_pgdata:/var/lib/postgresql/
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${DB_USER} -d account_db" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped


  contest_service:
    build: ContestService
    hostname: contest.service
    environment:
      SECRET_KEY: ${SECRET_KEY}
      PG_USER: ${DB_USER}
      PG_PASS: ${DB_PASS}
      PG_HOST: contest_db
      PG_PORT: 5432
      MODE: production
      RMQ_ADDRESS: rabbitmq
      RMQ_USER: ${RMQ_USER}
      RMQ_PASS: ${RMQ_PASSWORD}
      ENCODING: ${GLOBAL_ENCODING}
      ACCOUNT_SERVICE: "http://account.service:8000/api/v1/accounts"
      ALLOWED_HOSTS: "*"
      COMPILERS: ${COMPILERS}
      ALLOW_CONTEST_CREATION_TO: "Tapeline"
    ports:
      - "8002:8000"
    expose:
      - 8000
    networks:
      - main_network
    depends_on:
      contest_db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      account_service:
        condition: service_started

  contest_db:
    image: postgres:17.4
    hostname: contest_db
    environment:
      POSTGRES_DB: contest_db
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASS}
    expose:
      - "5432"
    ports:
      - "5501:5432"
    networks:
      - main_network
    volumes:
      - contest_pgdata:/var/lib/postgresql/
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${DB_USER} -d contest_db" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped


  minio:
    image: minio/minio:latest
    command: server --console-address ":9001" /data/
    hostname: minio
    ports:
      - "9900:9000"
      - "9901:9001"
    expose:
      - 9000
      - 9001
    environment:
      MINIO_ROOT_USER: ${MINIO_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_PASS}
      MINIO_BROWSER_REFERRER_POLICY: "unsafe-url"
    volumes:
      - minio_data:/data
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - main_network


  solution_service:
    build: SolutionService
    hostname: solution.service
    environment:
      SOLUTION_SVC_POSTGRES__USER: ${DB_USER}
      SOLUTION_SVC_POSTGRES__PASS: ${DB_PASS}
      SOLUTION_SVC_POSTGRES__HOST: solution_db
      SOLUTION_SVC_POSTGRES__PORT: 5432
      SOLUTION_SVC_POSTGRES__NAME: solution_db
      SOLUTION_SVC_MODE: production
      SOLUTION_SVC_DEBUG_MODE: True
      SOLUTION_SVC_RABBITMQ__HOST: rabbitmq
      SOLUTION_SVC_RABBITMQ__USER: ${RMQ_USER}
      SOLUTION_SVC_RABBITMQ__PASS: ${RMQ_PASSWORD}
      SOLUTION_SVC_ENCODING: ${GLOBAL_ENCODING}
      SOLUTION_SVC_SERVICES__ACCOUNT_SERVICE: "http://account.service:8000/api/v1/accounts"
      SOLUTION_SVC_SERVICES__CONTEST_SERVICE: "http://contest.service:8000/api/v1"
      SOLUTION_SVC_SERVICES__CONTEST_SERVICE_INTERNAL: "http://contest.service:8000/internal"
      SOLUTION_SVC_S3__HOST: "http://minio"
      SOLUTION_SVC_S3__PORT: 9000
      SOLUTION_SVC_S3__USER: ${MINIO_USER}
      SOLUTION_SVC_S3__PASS: ${MINIO_PASS}
      SOLUTION_SVC_ALLOWED_HOSTS: "*"
    ports:
      - "8003:8000"
    expose:
      - 8000
    networks:
      - main_network
    configs:
      - source: solution_service_cfg
        target: /app/solution_service.yml
    depends_on:
      solution_db:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      account_service:
        condition: service_started
      contest_service:
        condition: service_started

  solution_db:
    image: postgres:13.3
    hostname: solution_db
    environment:
      POSTGRES_DB: solution_db
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASS}
    expose:
      - "5432"
    ports:
      - "5503:5432"
    networks:
      - main_network
    volumes:
      - solution_pgdata:/var/lib/postgresql/
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U ${DB_USER} -d solution_db" ]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped


  frontend_service:
    build: Frontend
    hostname: frontend.service
    expose:
      - 3000
    networks:
      - main_network


  api_gateway:
    image: nginx:alpine
    hostname: api.service
    command: nginx -g "daemon off;"
    restart: on-failure
    volumes:
      - ./api_gateway_nginx.conf:/etc/nginx/nginx.conf
      #- ./sslcert/fullchain.pem:/etc/nginx/server.crt
      #- ./sslcert/privkey.pem:/etc/nginx/server.key
    ports:
    #  - "443:443"
      - "8888:80"
      - "80:80"
    networks:
      - main_network
    depends_on:
      account_service:
        condition: service_started
      contest_service:
        condition: service_started
      #solution_service:
      #  condition: service_started


  grafana:
    build: Grafana
    container_name: grafana
    restart: unless-stopped
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
    networks:
      - main_network
      - monitoring_network
    healthcheck:
      test: [ "CMD", "grafana-cli", "plugins", "ls" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  prometheus:
    build: Prometheus
    container_name: prometheus
    hostname: prometheus
    volumes:
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    restart: always
    expose:
      - 9090
    ports:
      - "9090:9090"
    networks:
      - monitoring_network
      - main_network
      - judgelet_network
    labels:
      org.label-schema.group: "monitoring"

#  alertmanager:
#    build: Alertmanager
#    container_name: alertmanager
#    command:
#      - '--config.file=/etc/alertmanager/config.yml'
#      - '--storage.path=/alertmanager'
#    restart: always
#    expose:
#      - 9093
#    networks:
#      - monitoring_network
#    labels:
#      org.label-schema.group: "monitoring"

  nodeexporter:
    image: prom/node-exporter:v1.3.1
    hostname: nodeexporter
    container_name: nodeexporter
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    restart: always
    expose:
      - 9100
    networks:
      - monitoring_network
    labels:
      org.label-schema.group: "monitoring"

  loki:
    hostname: loki
    container_name: loki
    build: Loki
    command: -config.file=/etc/loki/loki-config.yaml
    expose:
      - 3100
    restart: always
    networks:
      - monitoring_network

  promtail:
    build: Promtail
    container_name: promtail
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/log:/var/log:ro
    command: -config.file=/etc/promtail/promtail-config.yaml
    restart: always
    networks:
      - monitoring_network
      - main_network
      - judgelet_network

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.52.1
    container_name: cadvisor
    hostname: cadvisor
    privileged: true
    ports:
      - "3200:8080"
    devices:
      - /dev/kmsg:/dev/kmsg
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
      - /etc/machine-id:/etc/machine-id:ro
    restart: always
    expose:
      - 8080
    networks:
      - monitoring_network
    labels:
      org.label-schema.group: "monitoring"

  nginx-prometheus-exporter:
    image: nginx/nginx-prometheus-exporter:1.0
    container_name: prometheus-nginx-exporter
    hostname: promexporter.service
    restart: always
    command:
      - -nginx.scrape-uri=http://api.service:4000/nginx_status
    expose:
      - 9113
    networks:
      - main_network



networks:
  main_network:
    driver: bridge
  judgelet_network:
    driver: bridge
  monitoring_network:
    driver: bridge



volumes:
  account_pgdata:
  contest_pgdata:
  solution_pgdata:
  rabbitmq_data:
  minio_data:
  prometheus_data:
  grafana_data:
  loki_data:



configs:
  account_service_cfg:
    file: AccountService/account_service.yml
  solution_service_cfg:
    file: SolutionService/solution_service.yml
